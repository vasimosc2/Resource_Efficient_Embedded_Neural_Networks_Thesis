\chapter{Introduction}

\section{Background \& Motivation}

The rapid expansion of the Internet of Things (IoT) ecosystem has led to widespread deployment of embedded devices equipped with sensors and low-power microcontrollers. These devices are expected to operate continuously in energy- and memory-constrained environments, often disconnected from cloud services. Offloading raw sensor data to centralized servers for processing introduces latency, energy costs, and privacy risks. This has sparked significant interest in \textbf{Tiny Machine Learning (TinyML)}—a field that focuses on running neural networks entirely on-device.

TinyML enables applications such as on-device speech recognition, gesture detection, and image classification, especially in always-on sensors, wearables, and smart home devices. To make this feasible, researchers have developed compact and efficient deep learning models tailored to edge hardware. \textbf{MobileNets}, for example, leverage depthwise separable convolutions to build lightweight convolutional neural networks (CNNs) that perform well on mobile vision tasks while maintaining low computational cost~\cite{ConvNetworksMobileNets}. \textbf{EfficientNet} extends this idea by using compound scaling to balance depth, width, and resolution for optimal accuracy under resource constraints~\cite{tan2019efficientnet}.

Other techniques such as \textbf{network pruning} and \textbf{quantization} further compress models by eliminating redundant parameters and reducing numeric precision, respectively. Together, these strategies have significantly advanced \textbf{resource-efficient deep learning}, enabling inference on smartphones and edge devices with modest resources~\cite{alajlan2022tinyml}.

Despite these advances, TinyML deployments face \textbf{tight hardware limits}. For example, the Arduino Nano 33 BLE Sense has only 256\,KB of RAM and 1\,MB of flash memory. Under such constraints, even a quantized MobileNet-V2 may exceed available memory. These conditions demand highly compact architectures and efficient inference libraries optimized for microcontrollers.

While hand-designed architectures have made remarkable progress, manually crafting efficient models is time-consuming and often suboptimal. \textbf{Neural Architecture Search (NAS)} was proposed as a solution to this challenge: it automates the design of high-performance neural networks by systematically exploring large architecture spaces~\cite{liu2022survey}. NAS has produced architectures that match or surpass human-designed models on image classification benchmarks like CIFAR-10 and CIFAR-100.

However, NAS remains \textbf{computationally expensive}. For example, Liu et al. used a reinforcement learning–based NAS framework to design a model for CIFAR-10, requiring 28 days of computation on 800 GPUs~\cite{liu2022survey}. Such computational demands make NAS inaccessible to most researchers and wholly unsuitable for deployment on-device. Moreover, most NAS frameworks are not designed to be hardware-aware; they do not account for the strict memory, latency, and energy constraints of microcontroller-class devices.

This thesis is motivated by the need to make NAS both \textbf{efficient} and \textbf{hardware-aware}. We aim to explore novel strategies—such as lightweight evaluation proxies and search-space constraints—that can reduce redundant computation, guide the search more intelligently, and produce architectures that are deployable on real-world embedded platforms. By developing a more efficient NAS pipeline, this work contributes to making automated model design feasible for TinyML applications.

\section{Problem Statement}

\TODO{I think there is repetition with what it was stated before}
The growth of TinyML has unlocked the possibility of deploying deep learning models directly on resource-constrained embedded devices. However, designing neural network architectures that are both accurate and lightweight enough to run on microcontrollers remains a significant challenge.

Transmitting sensor data to the cloud is costly in terms of latency, energy, and privacy. Running inference locally avoids these costs but requires models that are extremely compact and efficient. Techniques such as quantization, pruning, and architectural innovations like depthwise convolutions have made it possible to shrink models. Yet, these approaches often rely on \textbf{manual design}, which is time-intensive and may not yield optimal results for all tasks or devices.

\textbf{Neural Architecture Search (NAS)} offers a solution by automating the model design process. However, existing NAS approaches are not well-suited for embedded environments:
\begin{itemize}
    \item They typically require \textbf{significant computational resources}—many GPU-days or weeks of training.
    \item They often \textbf{ignore hardware constraints}, failing to enforce limits on memory usage, parameter count, or inference latency during the search.
\end{itemize}

These shortcomings make NAS impractical for TinyML scenarios and limit its adoption in low-power, memory-constrained platforms like the Arduino Nano 33 BLE.

Thus, the \textbf{core problem} addressed in this thesis is twofold:


\begin{enumerate}
    \item \textbf{How can we drastically accelerate NAS}, making it computationally feasible for small-scale research and practical deployment?
    \item \textbf{How can we incorporate hardware-awareness into the NAS process}, ensuring that discovered architectures meet strict constraints in terms of memory, latency, and computational budget?
\end{enumerate}

Solving these challenges will help bridge the gap between NAS research and real-world deployment on microcontrollers, bringing automated deep learning closer to the edge.








\section{Research Objectives}

The primary objective of this research is to develop a resource-efficient Neural Architecture Search (NAS) framework capable of rapidly discovering and deploying optimized neural network models on constrained embedded platforms. Specifically, the research aims to accelerate a NAS algorithm, based on a Genetic Algorithm (GA), tailored for the CIFAR-100 image classification dataset, while ensuring that the resulting models are efficient enough to run on microcontroller hardware.

To achieve this overarching goal, the following specific research objectives are pursued:
 
\begin{enumerate}
    \item \textbf{Design a custom NAS algorithm using a Genetic Algorithm (GA):} Develop a NAS approach that leverages evolutionary strategies to automatically explore convolutional neural network architectures for the CIFAR-100 dataset (which consists of 60,000 32$\times$32 images across 100 classes~\cite{cifar}). 
    
    The choice of a GA is motivated by its ability to perform global search and handle multi-objective optimization, and by prior successes of evolutionary methods in architecture search. This objective includes defining an appropriate search space and genetic encoding for candidate network architectures.

    \TODO{Again this thing that it is slow is Repeted in the Introduction}
    \item \textbf{Accelerate the NAS search process:} Improve the speed and computational efficiency of the NAS algorithm so that high-performing network architectures can be identified with significantly reduced search time. Conventional NAS techniques are notoriously time-consuming and computationally expensive---for example, early NAS experiments required on the order of tens of thousands of GPU-hours~\cite{pham2018efficient}. In this work, the NAS algorithm is optimized to converge more quickly to promising architectures. The goal is to reduce the overall time and resources needed for the search, making NAS feasible without access to vast compute resources.



    \item \textbf{Deploy and evaluate the optimized model on hardware:} Take the best evolved neural network architectures and deploy them on the Arduino Nano 33 BLE platform to validate their real-world performance. This involves converting or quantizing the model (e.g., via TensorFlow Lite for Microcontrollers) and measuring on-device metrics such as inference latency, memory usage (RAM/Flash consumption), and classification accuracy. By profiling the deployed model, the research can confirm that the networks indeed operate within the device’s memory and processing limits. Analyzing these performance metrics will also help in identifying any bottlenecks (e.g., additional RAM and Flash consumption other than our model) and in demonstrating that the project’s improvements meet the targeted objectives. In summary, this objective ensures that the NAS-generated model is not only theoretically efficient but also practically viable on a real embedded device, thereby closing the loop from algorithm design to embedded deployment.
\end{enumerate}


\section{Scope}

The scope of this thesis is deliberately limited to a well-defined application area and methodological framework, as outlined below:

\subsection{Target Problem and Dataset}

This work is centered on an image classification task using the CIFAR-100 dataset. All experiments and evaluations use CIFAR-100 as the benchmark problem, and the NAS algorithm is specifically tailored to this dataset. Other datasets or machine learning tasks (e.g., CIFAR-10, ImageNet, object detection, or speech recognition) are outside the scope of this research. Focusing on CIFAR-100—a relatively complex vision dataset with 100 classes—provides a challenging test case for the NAS algorithm, while remaining tractable for experimentation within the resource and time constraints of a master’s thesis.

\subsection{Neural Architecture Search Methodology}

The research employs a custom Genetic Algorithm (GA) for neural architecture search. This evolutionary approach to NAS is the sole search strategy implemented and studied in depth. Alternative NAS techniques—such as reinforcement learning-based controllers or differentiable NAS methods—are not implemented in this project. These methods may be discussed in the literature review for context, but no comparative analysis is conducted. The decision to use a GA defines the methodological scope: all improvements and observations are made in the context of evolutionary search. The thesis does not attempt to develop new reinforcement learning algorithms or gradient-based NAS; instead, it strictly investigates how a GA-driven NAS can be accelerated and made hardware-aware.

\subsection{Embedded Deployment Focus}

The resulting neural network models are optimized for deployment on microcontroller-based platforms, with the Arduino Nano 33 BLE serving as the primary reference device for evaluation. This board, featuring an Arm Cortex-M4F MCU running at 64\,MHz with 1\,MB flash and 256\,KB RAM~\cite{ArduinoNano}, exemplifies the type of resource-constrained embedded hardware targeted in this work. All optimization techniques---such as model compression and quantization---were guided by the constraints of such devices. Although deployment experiments were carried out specifically on the Arduino Nano 33 BLE, the developed code and methodology are designed to be portable across similar embedded platforms. Standard embedded ML toolchains, such as TensorFlow Lite for Microcontrollers, were used for inference, ensuring broad applicability beyond the specific hardware reference. By focusing the deployment on a single, well-characterized device, the research enables consistent evaluation under known resource constraints, while retaining generalizability to other comparable microcontroller-based systems.


\clearpage

\subsection{Performance Metrics}

This research defines a clear set of metrics to evaluate both the quality and practical viability of the neural network models generated through the NAS process. These metrics are chosen to align closely with the constraints and goals of deploying deep learning models on ultra-low-power embedded systems. The metrics are considered at two key stages of the workflow:
\begin{itemize}
    \item During the NAS process, to guide architecture selection and pruning via predictive models and constraint checks.
\end{itemize}
\begin{itemize}
    \item After deployment on hardware, to validate actual on-device behavior and efficiency.
\end{itemize}
The primary performance metrics are the following:

\begin{comment}
\textbf{Inference latency}

This refers to the time it takes for the deployed model to process an input and produce a prediction on the Arduino Nano 33 BLE. Latency is critical in real-time embedded applications—such as gesture recognition, audio processing, or sensor data classification—where delayed responses can compromise functionality or user experience. Measuring latency ensures that the model is fast enough for time-sensitive applications.
\end{comment}


\textbf{Memory usage}

Memory efficiency is assessed in two dimensions:
\begin{itemize}
    \item \textbf{\textit{Static memory usage (Flash)}:} This includes the size of the compiled model binary (weights, parameters, and code) stored in the microcontroller's non-volatile flash memory. The total must remain under the 1MB limit of the Arduino Nano 33 BLE.

    \item \textbf{\textit{Runtime memory usage (RAM)}:} This includes memory used during inference (activations, buffers, stack, and heap). Since the target device only has 256KB of RAM, models must be sufficiently compact to run within this tight constraint. Excessive RAM usage can lead to runtime errors or unpredictable behavior.
\end{itemize}

\textbf{Classification accuracy}

Although the focus is on efficiency, model accuracy on the CIFAR-100 dataset remains a key metric. The objective is to maintain as high accuracy as possible while minimizing model complexity. This trade-off between performance and resource usage is at the core of this thesis, and all evaluated architectures are measured for their top-1 classification accuracy on a held-out test set.

\textbf{Energy Consumption}

Energy efficiency is a critical concern for embedded systems. In this work, direct power measurements were successfully performed to quantify energy consumption, using appropriate tools to capture metrics such as power draw (in milliwatts) and energy usage (in joules). These measurements enabled a more rigorous evaluation of the models' efficiency on embedded hardware. Alongside these quantitative assessments, the design choices—such as minimizing model size, computation, and memory access—further contributed to reducing overall energy consumption.

\clearpage

\subsection{\textbf{Limitations and Exclusions}}

Certain performance aspects are acknowledged but fall outside the scope of this study due to resource or technical constraints:

\paragraph{\textbf{On-Device Deployment and Evaluation}:}
This thesis does not investigate training neural networks directly on the microcontroller. All model training and architecture search are conducted using conventional computing resources. The role of the embedded device—specifically, the Arduino Nano 33 BLE—is limited to deployment and evaluation tasks.

\begin{comment}
Deployment on the microcontroller serves two main purposes: (1) verifying that the models fit within the device’s memory limits (1~MB flash and 256~KB RAM), and (2) measuring the energy consumption during inference. It is important to note, however, that the actual available memory for model deployment is lower than the nominal specifications, due to system overhead and runtime allocations. Therefore, on-device deployment provides practical insight into the true usable memory budget available for models.

This approach reflects realistic usage scenarios, where microcontrollers are employed for energy-efficient inference under strict resource constraints, while the computationally intensive training phase is carried out off-device.
 
\end{comment}



\subsection{\textbf{Summary}}

By focusing on these well-defined and measurable performance metrics, the thesis ensures that the proposed NAS framework and the resulting models are not only theoretically sound but also practically deployable. The approach emphasizes real-world constraints, which are often overlooked in academic work, thereby bridging the gap between deep learning research and embedded systems deployment.


