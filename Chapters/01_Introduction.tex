\chapter{Introduction}
The rapid growth of Internet-of-Things (IoT) devices has created a demand for local intelligence on tiny embedded systems. IoT endpoints are often equipped with sensors and simple microcontrollers that must operate continuously; however, such devices typically have very limited computational and memory resources.

Transmitting raw sensor data to the cloud for processing incurs latency, energy, and privacy costs. In response, the emerging field of Tiny Machine Learning (TinyML) has shown how compact neural networks can be run entirely on-device, alleviating the need for cloud connectivity. Performing inference locally on the device reduces response latency and communication bandwidth, and it improves energy efficiency and privacy.\cite{alajlan2022tinyml}

These advances have enabled applications such as on-device vision and speech recognition in always-on sensors, wearables, and smart home devices. To meet the constraints of TinyML platforms, researchers have explored designing efficient neural networks. For example, MobileNets use depthwise separable convolutions and simple hyperparameters to build lightweight CNNs for mobile vision
\cite{ConvNetworks-MobileNets} 
In a similar spirit, EfficientNet introduces a compound scaling method that simultaneously balances network depth, width, and input resolution to maximize accuracy under resource budgets. \cite{tan2019efficientnet}

These designs demonstrate that convolutional neural networks (CNNs) can be orders of magnitude smaller than standard models while maintaining high accuracy. Other techniques, such as network pruning and quantization, also reduce model size and speed up inference on constrained hardware. Together, these efforts have greatly advanced resource-efficient deep learning, enabling vision models to run on smartphones and edge devices with modest computation.

\todo{See how you can add here the budget.}

Under this budget, even quantized MobileNet-V2 exceeds the memory limit. These tight hardware limits demand highly compact neural architectures and efficient inference libraries tailored to microcontrollers. Despite the promise of TinyML, automatically finding suitable network architectures remains a challenge. Neural Architecture Search (NAS) aims to automate the design of neural networks by searching over a space of candidate architectures
 \cite{liu2022survey}

NAS has shown remarkable results on standard benchmarks (e.g. automatically discovered models that match or exceed human-designed networks on CIFAR-10/100 arxiv.org).

However, NAS is notoriously computationally expensive. Liu et al. note that NAS is still “laborious and time-consuming” because it requires evaluating a large number of candidate networks \cite{liu2022survey} .

For example, Liu et al. used a reinforcement-learning controller to search for a CIFAR-10 model and spent 28 days on 800 high-end GPUs to complete the search
cite{liu2022survey} 

Such a computational burden puts NAS beyond the reach of most researchers and prohibits on-device NAS. Compounding the difficulty, an effective NAS for embedded systems must enforce hardware constraints during search. In practice, this means the search must find architectures that meet tight limits on parameters, memory footprint, and latency.

In the context of microcontrollers, failure to honor constraints renders a model useless: an architecture that can’t fit in 320 KB of RAM will never run on the target device. Thus the core problem is twofold: 

\textbf{First}, how to drastically accelerate NAS so that viable architectures can be found without supercomputing resources, and

\textbf{Second}, how to ensure the found architectures satisfy the severe hardware constraints of tiny embedded platforms.

\section{This is a section}
Every chapter is numbered and the sections inherit the chapter number followed by a dot and a section number. Figures, equations, tables, ect. also inherit the chapter numbering. 

\subsection{This is a sub section}
Sub sections are also numbered. In general try not to use a deep hierarchy of sub sections (\texttt{\textbackslash paragraph\{\}} and the like). The document will become segmented which will make the document appear less coherent. 

\subsubsection{This is a sub sub section}
And those are not numbered. It is possible to adjust how deep hierarchy of numbering sections goes in Setup/Settings.tex. 

The front and back cover have been made to replicate the examples in the design guide \url{https://www.designguide.dtu.dk/#stnd-printmedia}. The name of department heading is omitted  because it is located in the top right corner (no need to write it twice). Take a look at \url{https://www.inside.dtu.dk/en/medarbejder/om-dtu-campus-og-bygninger/kommunikation-og-design/skabeloner/rapporter} if you want to make your cover separately. 

Citing is done with the \texttt{biblatex} package \cite{publication1}. Cross referencing (figures, tables, ect.) is taken care by the \texttt{cleveref} package. Just insert the name of the label in \textbackslash \texttt{cref\{\}} and it will automatically format the cross reference. For example writing the \texttt{cleveref} command \textbackslash \texttt{cref\{fig:groupedcolumn\}} will output ``\cref{fig:groupedcolumn}''. Using \textbackslash \texttt{Cref\{\}} will capitalise the first letter and \textbackslash \texttt{crefrange\{\}\{\}} will make a reference range. An example: \Cref{fig:stackedbar} is an example of a stacked bar chart and \crefrange{fig:stackedcolumn}{fig:groupedcolumn} are three consecutive figures.

\section{Font and symbols test}
Symbols can be written directly in the document meaning there is no need for special commands to write special characters. I love to write special characters like æøå inside my \TeX{} document. Also á, à, ü, û, ë, ê, î, ï could be nice. So what about the ``¿'' character. What about ° é ® † ¥ ü | œ ‘ @ ö ä ¬ ‹ « © ƒ ß ª … ç ñ µ ‚ · ¡ “ £ ™ [ ] '. Some dashes - – —, and the latex form - -- --- 

This is a font test \newline 
Arial Regular \newline 
\textit{Arial Italic} \newline 
\textbf{Arial Bold} \newline 
\textbf{\textit{Arial Bold Italic}}
