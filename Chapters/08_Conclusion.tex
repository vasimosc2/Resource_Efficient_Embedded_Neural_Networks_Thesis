\chapter{Conclusion}

This thesis presented a comprehensive framework for optimizing the black box of the Neural Architecture Search (NAS) algorithm with the primary objective of enabling the automated design of deep learning models suitable for highly constrained embedded environments, such as the Arduino Nano 33 BLE Sense.

The research centered around improving a Genetic Algorithm-based NAS framework, enhanced through multiple layers of optimization: intelligent memory estimations, early-stopping strategies, and RankNet experiment.

This study introduced a hardware-aware, resource-efficient NAS pipeline centered on a Genetic Algorithm (GA), carefully engineered to explore architectural variations of the TakuNet model. A key innovation was the integration of a RankNet-based surrogate model to accelerate search convergence by approximating relative model performance, thereby drastically reducing the need for full model training and evaluation during the search process.

To ensure deployability, the framework included robust memory estimation, full integer quantization workflows, and real-time deployment tests. The methodology balanced inference accuracy, memory footprint, and latency, confirming that evolved architectures met the strict computational and memory limits of microcontroller-class devices. TakuNet, as the baseline architecture, proved highly effective when optimized through the NAS process, offering both structural modularity and performance scalability.

Experimental results validated that the optimized NAS approach could yield high-performing, quantized models that not only rival conventional hand-crafted architectures but also fit within stringent embedded hardware constraints. The successful deployment and execution of these models on the Arduino platform underscored the practical viability of the proposed solution.

In summary, this work demonstrated that through intelligent NAS optimization—particularly by combining evolutionary strategies with predictive modeling—it is possible to democratize neural architecture design for edge AI applications. The presented framework bridges the gap between AutoML research and real-world embedded deployment, paving the way for further advancements in TinyML and ultra-efficient deep learning systems.



