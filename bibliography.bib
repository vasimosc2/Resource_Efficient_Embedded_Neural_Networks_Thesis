@online{publication1,
  title = {Biblatex – Sophisticated Bibliographies in LaTeX},
  publisher = {Dansk Standard},
  year = {2018},
  author = {Philipp Lehman AND Joseph Wright AND Audrey Boruvka AND Philip Kime},
  url = {https://www.ctan.org/pkg/biblatex}
}
@inproceedings{Wang_2020_CVPR,
author = {Wang, Ning and Gao, Yang and Chen, Hao and Wang, Peng and Tian, Zhi and Shen, Chunhua and Zhang, Yanning},
title = {NAS-FCOS: Fast Neural Architecture Search for Object Detection},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2020}
}
@inproceedings{jacob2018quantization,
  title={Quantization and training of neural networks for efficient integer-arithmetic-only inference},
  author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2704--2713},
  year={2018}
}

@misc{tensorflow_quantization,
  author = {TensorFlow},
  title = {Post-training quantization},
  year = {2025},
  url = {https://www.tensorflow.org/model_optimization/guide/quantization/post_training},
}

@misc{tensorflow_representativedataset,
  author = {TensorFlow},
  title = {RepresentativeDataset API documentation},
  year = {2025},
  url = {https://www.tensorflow.org/api_docs/python/tf/lite/RepresentativeDataset},
}


@misc{tensorflow_RamEstimation,
  author = {TensorFlow},
  title = {Optimizing TensorFlow Lite Runtime Memory},
  year = {2025},
  url = {https://blog.tensorflow.org/2020/10/optimizing-tensorflow-lite-runtime.html#:~:text=the%20model%20itself,large%20as%20the%20model%20itself},
}



@article{liberis2019neural,
  title={Neural networks on microcontrollers: saving memory at inference via operator reordering},
  author={Liberis, Edgar and Lane, Nicholas D},
  journal={arXiv preprint arXiv:1910.05110},
  year={2019}
}

@article{pau2023tiny,
  title={Tiny machine learning zoo for long-term compensation of pressure sensor drifts},
  author={Pau, Danilo and Ben Yahmed, Welid and Aymone, Fabrizio Maria and Licciardo, Gian Domenico and Vitolo, Paola},
  journal={Electronics},
  volume={12},
  number={23},
  pages={4819},
  year={2023},
  publisher={MDPI}
}
@article{manor2022custom,
  title={Custom hardware inference accelerator for tensorflow lite for microcontrollers},
  author={Manor, Erez and Greenberg, Shlomo},
  journal={IEEE Access},
  volume={10},
  pages={73484--73493},
  year={2022},
  publisher={IEEE}
}

@article{TakuNet,
  title={TakuNet: an Energy-Efficient CNN for Real-Time Inference on Embedded UAV systems in Emergency Response Scenarios},
  author={Rossi, Daniel and Borghi, Guido and Vezzani, Roberto},
  journal={arXiv preprint arXiv:2501.05880},
  year={2025}
}

@article{inferenceTime1,
  title={Machine Learning for Microcontroller-Class Hardware: A Review},
  author={Saha, Swapnil Sayan and Sandha, Sandeep Singh and Srivastava, Mani},
  journal={IEEE Sensors Journal}, 
  year={2022},
  volume={22},
  number={22},
  pages={21362-21390},
  keywords={Microcontrollers;Sensors;Data models;Hardware;Random access memory;Mathematical models;Computational modeling;Feature projection;Internet of Things;machine learning (ML);microcontrollers;model compression;neural architecture search (NAS);neural networks;optimization;sensors;TinyML},
  doi={10.1109/JSEN.2022.3210773}
}

@article{ConvNetworksMobileNets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}


@inproceedings{BatchNorm,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={pmlr}
}

@article{Dropout,
  title={Adaptive dropout for training deep neural networks},
  author={Ba, Jimmy and Frey, Brendan},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@inproceedings{chollet2017xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Fran{\c{c}}ois},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1251--1258},
  year={2017}
}

@inproceedings{zhou2021resnext,
  title={Resnext and res2net structures for speaker verification},
  author={Zhou, Tianyan and Zhao, Yong and Wu, Jian},
  booktitle={2021 IEEE Spoken Language Technology Workshop (SLT)},
  pages={301--307},
  year={2021},
  organization={IEEE}
}

@inproceedings{PointwiseGroupedCon,
  title={Grouped pointwise convolutions reduce parameters in convolutional neural networks},
  author={Schuler, Joao Paulo Schwarz and Romani, Santiago and Abdel-Nasser, Mohamed and Rashwan, Hatem and Puig, Domenec},
  booktitle={Mendel},
  volume={28},
  number={1},
  pages={23--31},
  year={2022}
}

@misc{alajlan2022tinyml,
  title={TinyML: enabling of inference deep learning models on ultra-low-power IoT edge devices for AI applications,” Micromachines, 13 (6): 851},
  author={Alajlan, NN and Ibrahim, DM},
  year={2022}
}

@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@article{lin2020mcunet,
  title={Mcunet: Tiny deep learning on iot devices},
  author={Lin, Ji and Chen, Wei-Ming and Lin, Yujun and Gan, Chuang and Han, Song and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={11711--11722},
  year={2020}
}

@article{liu2022survey,
  title={A survey on computationally efficient neural architecture search},
  author={Liu, Shiqing and Zhang, Haoyu and Jin, Yaochu},
  journal={Journal of Automation and Intelligence},
  volume={1},
  number={1},
  pages={100002},
  year={2022},
  publisher={Elsevier}
}

@article{hussain2020trade,
  title={Trade-off between exploration and exploitation with genetic algorithm using a novel selection operator},
  author={Hussain, Abid and Muhammad, Yousaf Shad},
  journal={Complex \& intelligent systems},
  volume={6},
  number={1},
  pages={1--14},
  year={2020},
  publisher={Springer}
}

@article{filipovic2003fine,
  title={Fine-grained tournament selection operator in genetic algorithms},
  author={Filipovi{\'c}, Vladimir},
  journal={Computing and Informatics},
  volume={22},
  number={2},
  pages={143--161},
  year={2003}
}

@article{RankNet,
  title={Surrogate-assisted evolutionary neural architecture search with network embedding},
  author={Fan, Liang and Wang, Handing},
  journal={Complex \& Intelligent Systems},
  volume={9},
  number={3},
  pages={3313--3331},
  year={2023},
  publisher={Springer}
}

@article{achille2017critical,
  title={Critical learning periods in deep neural networks},
  author={Achille, Alessandro and Rovere, Matteo and Soatto, Stefano},
  journal={arXiv preprint arXiv:1711.08856},
  year={2017}
}

@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}
@article{lewkowycz2021decay,
  title={How to decay your learning rate},
  author={Lewkowycz, Aitor},
  journal={arXiv preprint arXiv:2103.12682},
  year={2021}
}

@misc{cifar,
  author       = {Alex Krizhevsky},
  title        = {Learning Multiple Layers of Features from Tiny Images},
  year         = {2009},
  howpublished = {\url{https://www.cs.toronto.edu/~kriz/cifar.html}},
  note         = {Accessed: 2025-05-17}
}

@inproceedings{pham2018efficient,
  title={Efficient neural architecture search via parameters sharing},
  author={Pham, Hieu and Guan, Melody and Zoph, Barret and Le, Quoc and Dean, Jeff},
  booktitle={International conference on machine learning},
  pages={4095--4104},
  year={2018},
  organization={PMLR}
}

@misc{ArduinoNano,
  author       = {Gilbert Tanner},
  title        = {Arduino Nano 33 BLE Sense Overview},
  year         = {2020},
  howpublished = {\url{https://gilberttanner.com/blog/arduino-nano-33-ble-sense-overview/}},
  note         = {Accessed: 2025-05-18}
}

@online{techtarget_embedded_system,
  author    = {{TechTarget Contributor}},
  title     = {What is an embedded system?},
  year      = {2024},
  url       = {https://www.techtarget.com/iotagenda/definition/embedded-system},
  note      = {Accessed: 2025-05-18},
  organization = {TechTarget},
}

@article{yamashita2018convolutional,
  title={Convolutional neural networks: an overview and application in radiology},
  author={Yamashita, Rikiya and Nishio, Mizuho and Do, Richard Kinh Gian and Togashi, Kaori},
  journal={Insights into imaging},
  volume={9},
  pages={611--629},
  year={2018},
  publisher={Springer}
}

@article{pau2023quantitative,
  title={A quantitative review of automated neural search and on-device learning for tiny devices},
  author={Pau, Danilo Pietro and Ambrose, Prem Kumar and Aymone, Fabrizio Maria},
  journal={Chips},
  volume={2},
  number={2},
  pages={130--141},
  year={2023},
  publisher={MDPI}
}

@inproceedings{BatchNormAndReLuOrder,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{qiu2023shortest,
  title={Shortest edit path crossover: A theory-driven solution to the permutation problem in evolutionary neural architecture search},
  author={Qiu, Xin and Miikkulainen, Risto},
  booktitle={International Conference on Machine Learning},
  pages={28422--28447},
  year={2023},
  organization={PMLR}
}

@article{liu2018darts,
  title={Darts: Differentiable architecture search},
  author={Liu, Hanxiao and Simonyan, Karen and Yang, Yiming},
  journal={arXiv preprint arXiv:1806.09055},
  year={2018}
}

@article{elsken2019neural,
  title={Neural architecture search: A survey},
  author={Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={55},
  pages={1--21},
  year={2019}
}

@article{chu2021darts,
  title={DARTS-: Robustly Stepping out of Performance Collapse Without Indicators},
  author={Chu, Xiangning and Zhang, Tianbao and Xu, Bo and Li, Jixiang and Zhai, Zheng and Liang, Xiaolin and Zhang, Xilin},
  journal={ICLR},
  year={2021}
}

@article{king2025micronas,
  title={MicroNAS for memory and latency constrained hardware aware neural architecture search in time series classification on microcontrollers},
  author={King, Tobias and Zhou, Yexu and R{\"o}ddiger, Tobias and Beigl, Michael},
  journal={Scientific Reports},
  volume={15},
  number={1},
  pages={7575},
  year={2025},
  publisher={Nature Publishing Group UK London}
}

@article{SuperNet,
  title={How does supernet help in neural architecture search?},
  author={Zhang, Yuge and Zhang, Quanlu and Yang, Yaming},
  journal={arXiv preprint arXiv:2010.08219},
  year={2020}
}

@article{zela2020understanding,
  title={Understanding and Robustifying Differentiable Architecture Search},
  author={Zela, Arber and Siems, Jan Hendrik and Hutter, Frank},
  journal={ICLR},
  year={2020}
}

@article{burrello2023enhancing,
  title={Enhancing neural architecture search with multiple hardware constraints for deep learning model deployment on tiny IoT devices},
  author={Burrello, Alessio and Risso, Matteo and Motetti, Beatrice Alessandra and Macii, Enrico and Benini, Luca and Pagliari, Daniele Jahier},
  journal={IEEE Transactions on Emerging Topics in Computing},
  volume={12},
  number={3},
  pages={780--794},
  year={2023},
  publisher={IEEE}
}